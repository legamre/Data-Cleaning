This project involves cleaning, deduplicating, and standardizing a dataset of company layoffs. The SQL scripts provided automate the process of preparing the data for analysis by addressing issues such as duplicate records, inconsistent data formats, and missing values.

[Data source](https://www.kaggle.com/datasets/swaptr/layoffs-2022)

Project Overview

This project aims to prepare a raw layoffs dataset for analysis by eliminating duplicate records, standardizing data formats, and handling missing values. The process involves creating staging tables to manipulate data safely before applying final changes to the main dataset.

Key Learnings

Data Deduplication: Efficiently remove duplicate records using ROW_NUMBER() and CTEs.
Data Standardization: Ensure consistency across text fields and date formats.
SQL Best Practices: Safely manipulate large datasets by using staging tables and stepwise transformations.

Contact

For questions, suggestions, or collaboration opportunities, feel free to reach out:

Email: herc.ju@gmail.com

[LinkedIn](https://www.linkedin.com/in/julesherc/)
